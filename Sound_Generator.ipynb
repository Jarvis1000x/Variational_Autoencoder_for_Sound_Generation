{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sound Generator.ipynb",
      "provenance": [],
      "mount_file_id": "18o5hc2-xA4EKrwtg7rIM88jDQc0sL4uV",
      "authorship_tag": "ABX9TyPrev6kWdQ/rw4Oj1QNp/e1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jarvis1000x/Variational_Autoencoder_for_Sound_Generation/blob/main/Sound_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9DvxLWpJN6r"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
        "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HKsJbSm8uUo"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq9s2sen9IBw"
      },
      "source": [
        "HOP_LENGTH = 256\n",
        "SAVE_DIR_ORIGNAL = \"/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/sample/original\"\n",
        "SAVE_DIR_GENERATED = \"/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/sample/generated\"\n",
        "MIN_MAX_VALUES_PATH = \"/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/data/min_max_values.pkl\"\n",
        "SPECTROGRAM_PATH = \"/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/data/spectrograms\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy76nhEzKC6y"
      },
      "source": [
        "class MinMaxNormaliser:\n",
        "    # MinMaxNormaliser applies min max normalisation to an array\n",
        "\n",
        "    def __init__(self, min_val, max_val):\n",
        "        self.min = min_val\n",
        "        self.max = max_val\n",
        "\n",
        "    def normalise(self, array):\n",
        "        norm_array = (array - array.min()) / (array.max() - array.min())\n",
        "        norm_array = norm_array * (self.max - self.min) + self.min\n",
        "        return norm_array\n",
        "\n",
        "    def denormalise(self, norm_array, original_min, original_max):\n",
        "        array = (norm_array - self.min) / (self.max - self.min)\n",
        "        array = array * (original_max - original_min) + original_min\n",
        "        return array\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ9VF-JfKEqs"
      },
      "source": [
        "class SoundGenerator:\n",
        "    # Sound generator is responsible for generating audio from spectrogram\n",
        "\n",
        "    def __init__(self, vae, hop_length):\n",
        "        self.vae = vae\n",
        "        self.hop_length = hop_length\n",
        "        self._min_max_normaliser = MinMaxNormaliser(0, 1)\n",
        "\n",
        "    def generate(self, spectrograms, min_max_values):\n",
        "        generated_spectrograms, latent_representations = self.vae.reconstruct(spectrograms)\n",
        "        signals = self.convert_spectrograms_to_audio(generated_spectrograms, min_max_values)\n",
        "        return signals, latent_representations\n",
        "\n",
        "    def convert_spectrograms_to_audio(self, spectrograms, min_max_values):\n",
        "        signals = []\n",
        "        for spectrogram, min_max_value in zip(spectrograms, min_max_values):\n",
        "            # 1 - reshape the log spectrogram\n",
        "            log_spectrogram = spectrogram[:, :, 0]\n",
        "\n",
        "            # 2 - apply denormalisation\n",
        "            denorm_log_spec = self._min_max_normaliser.denormalise(\n",
        "                log_spectrogram, min_max_value[\"min\"], min_max_value[\"max\"])\n",
        "\n",
        "            # 3 - log spectrogram -> spectrogram\n",
        "            spec = librosa.db_to_amplitude(denorm_log_spec)\n",
        "\n",
        "            # 4 - apply griffin-lim algo\n",
        "            signal = librosa.istft(spec, hop_length=self.hop_length)\n",
        "\n",
        "            # 5 - append signal to signals\n",
        "            signals.append(signal)\n",
        "\n",
        "        return signals\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diC90mxlPjo6"
      },
      "source": [
        "class VAE:\n",
        "    \"\"\"\n",
        "    VAE represents a Deep Convolutional Variational autoencoder\n",
        "    architecture with a mirrored encoder and decoder component.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_shape,\n",
        "                 conv_filters,\n",
        "                 conv_kernels,\n",
        "                 conv_strides,\n",
        "                 latent_space_dim):\n",
        "        self.input_shape = input_shape # [28, 28, 1]\n",
        "        self.conv_filters = conv_filters # [2, 4, 8]\n",
        "        self.conv_kernels = conv_kernels # [3, 5, 3]\n",
        "        self.conv_strides = conv_strides # [1, 2, 2]\n",
        "        self.latent_space_dim = latent_space_dim # 2\n",
        "        self.reconstruction_loss_weight = 1000000\n",
        "\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.model = None\n",
        "\n",
        "        self._num_conv_layers = len(conv_strides)\n",
        "        self._shape_before_bottleneck = None\n",
        "        self._model_input = None\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def summary(self):\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "        self.model.summary()\n",
        "\n",
        "    def compile(self, learning_rate=0.0001):\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        self.model.compile(optimizer=optimizer,\n",
        "                           loss=self._calculate_combined_loss)\n",
        "\n",
        "    def train(self, x_train, batch_size, num_epochs):\n",
        "        self.model.fit(x_train,\n",
        "                       x_train,\n",
        "                       batch_size=batch_size,\n",
        "                       epochs=num_epochs,\n",
        "                       shuffle=True)\n",
        "\n",
        "    def save(self, save_folder=\".\"):\n",
        "        self._create_folder(save_folder)\n",
        "        self._save_parameters(save_folder)\n",
        "        self._save_weights(save_folder)\n",
        "\n",
        "    def _create_folder(self, folder):\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "\n",
        "    def _save_parameters(self, save_folder):\n",
        "        parameters = [\n",
        "            self.input_shape,\n",
        "            self.conv_filters,\n",
        "            self.conv_kernels,\n",
        "            self.conv_strides,\n",
        "            self.latent_space_dim\n",
        "        ]\n",
        "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            pickle.dump(parameters, f)\n",
        "\n",
        "    def _save_weights(self, save_folder):\n",
        "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
        "        self.model.save_weights(save_path)\n",
        "\n",
        "    def load_weights(self, weights_path):\n",
        "        self.model.load_weights(weights_path)\n",
        "\n",
        "    def reconstruct(self, images):\n",
        "        latent_representations = self.encoder.predict(images)\n",
        "        reconstructed_images = self.decoder.predict(latent_representations)\n",
        "        return reconstructed_images, latent_representations\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, save_folder=\".\"):\n",
        "        parameters_path = \"/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/model/parameters.pkl\"\n",
        "        with open(parameters_path, \"rb\") as f:\n",
        "            parameters = pickle.load(f)\n",
        "        autoencoder = VAE(*parameters)\n",
        "        weights_path = \"/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/model/weights.h5\"\n",
        "        autoencoder.load_weights(weights_path)\n",
        "        return autoencoder\n",
        "\n",
        "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
        "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
        "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
        "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss + kl_loss\n",
        "        return combined_loss\n",
        "\n",
        "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
        "        error = y_target - y_predicted\n",
        "        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
        "        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -\n",
        "                               K.exp(self.log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def _build(self):\n",
        "        self._build_encoder()\n",
        "        self._build_decoder()\n",
        "        self._build_autoencoder()\n",
        "\n",
        "    def _build_autoencoder(self):\n",
        "        model_input = self._model_input\n",
        "        model_output = self.decoder(self.encoder(model_input))\n",
        "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
        "\n",
        "    def _build_decoder(self):\n",
        "        decoder_input = self._add_decoder_input()\n",
        "        dense_layer = self._add_dense_layer(decoder_input)\n",
        "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
        "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
        "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
        "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "\n",
        "    def _add_decoder_input(self):\n",
        "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
        "\n",
        "    def _add_dense_layer(self, decoder_input):\n",
        "        num_neurons = np.prod(self._shape_before_bottleneck)\n",
        "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
        "        return dense_layer\n",
        "\n",
        "    def _add_reshape_layer(self, dense_layer):\n",
        "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
        "\n",
        "    def _add_conv_transpose_layers(self, x):\n",
        "        \"\"\"Add conv transpose blocks\n",
        "        loop through all the conv layers in reverse order and\n",
        "        stop at the first layer\"\"\"\n",
        "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
        "            x = self._add_conv_transpose_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_transpose_layer(self, layer_index, x):\n",
        "        layer_num = self._num_conv_layers - layer_index\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding=\"same\",\n",
        "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
        "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
        "        return x\n",
        "\n",
        "    def _add_decoder_output(self, x):\n",
        "        conv_transpose_layer = Conv2DTranspose(\n",
        "            filters=1,\n",
        "            kernel_size=self.conv_kernels[0],\n",
        "            strides=self.conv_strides[0],\n",
        "            padding=\"same\",\n",
        "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
        "        )\n",
        "        x = conv_transpose_layer(x)\n",
        "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
        "        return output_layer\n",
        "\n",
        "    def _build_encoder(self):\n",
        "        encoder_input = self._add_encoder_input()\n",
        "        conv_layers = self._add_conv_layers(encoder_input)\n",
        "        bottleneck = self._add_bottleneck(conv_layers)\n",
        "        self._model_input = encoder_input\n",
        "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
        "\n",
        "    def _add_encoder_input(self):\n",
        "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
        "\n",
        "    def _add_conv_layers(self, encoder_input):\n",
        "        # Creates all convolutional blocks in encoder.\n",
        "        x = encoder_input\n",
        "        for layer_index in range(self._num_conv_layers):\n",
        "            x = self._add_conv_layer(layer_index, x)\n",
        "        return x\n",
        "\n",
        "    def _add_conv_layer(self, layer_index, x):\n",
        "        \"\"\"\n",
        "        Adds a convolutional block to a group to a graph of layers,\n",
        "        consisting of conv 2D + ReLU + batch Normalisation\n",
        "        \"\"\"\n",
        "        layer_number = layer_index + 1\n",
        "        conv_layer = Conv2D(\n",
        "            filters=self.conv_filters[layer_index],\n",
        "            kernel_size=self.conv_kernels[layer_index],\n",
        "            strides=self.conv_strides[layer_index],\n",
        "            padding=\"same\",\n",
        "            name=f\"encoder_conv_layer_{layer_number}\"\n",
        "        )\n",
        "        x = conv_layer(x)\n",
        "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
        "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
        "        return x\n",
        "\n",
        "    def _add_bottleneck(self, x):\n",
        "        # Flatten data and add bottleneck with Guassian sampling(Dense layer).\n",
        "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
        "        x = Flatten()(x)\n",
        "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
        "        self.log_variance = Dense(self.latent_space_dim,\n",
        "                                  name=\"log_variance\")(x)\n",
        "        # x = Dense(self.latent_space_dim, name=\"encoder_output\")(x)\n",
        "\n",
        "        def sample_point_from_normal_distribution(args):\n",
        "            mu, log_variance = args\n",
        "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0., stddev=1.)\n",
        "            sampled_point = mu + K.exp(log_variance/2)*epsilon\n",
        "            return sampled_point\n",
        "            \n",
        "        x = Lambda(sample_point_from_normal_distribution, name=\"encoder_output\")([self.mu, self.log_variance])\n",
        "        return x\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU7tU1s6Mhxd"
      },
      "source": [
        "def load_fsdd(spectrogram_path):\n",
        "    x_train = []\n",
        "    file_paths = []\n",
        "    for root, _, file_names in os.walk(spectrogram_path):\n",
        "        for file_name in file_names:\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            spectrogram = np.load(file_path, allow_pickle=True)\n",
        "            x_train.append(spectrogram)\n",
        "            file_paths.append(file_path)\n",
        "    x_train = np.array(x_train)\n",
        "    x_train = x_train[..., np.newaxis]\n",
        "    return x_train, file_paths\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SA5gmBBMnv_"
      },
      "source": [
        "def select_spectrograms(spectrograms,\n",
        "                        file_paths,\n",
        "                        min__max_values,\n",
        "                        num_spectrograms=2):\n",
        "    #sampled_indexes = np.random.choice(range(len(spectrograms)), num_spectrograms)\n",
        "\n",
        "    sampled_indexes = np.random.choice(range(len(spectrograms)), num_spectrograms)\n",
        "    sampled_spectrograms = spectrograms[sampled_indexes]\n",
        "\n",
        "    #sampled_spectrograms = spectrograms[sampled_indexes]\n",
        "    file_paths = [file_paths[index] for index in sampled_indexes]\n",
        "    sampled_min_max_values = [min__max_values[file_path] for file_path in file_paths]\n",
        "    print(file_paths)\n",
        "    print(sampled_min_max_values)\n",
        "    return sampled_spectrograms, sampled_min_max_values\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Eq2sfS0Ms2-"
      },
      "source": [
        "def save_signal(signals, save_dir, sample_rate=22050):\n",
        "    for i, signal in enumerate(signals):\n",
        "        save_path = os.path.join(save_dir, str(i) + \".wav\")\n",
        "        sf.write(save_path, signal, sample_rate)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr80_lS4MwT5",
        "outputId": "bd35fe36-d9e9-44f2-bb36-bebf9ca2adfe"
      },
      "source": [
        "# initialise sound generator\n",
        "vae = VAE.load(\"model\")\n",
        "sound_generator = SoundGenerator(vae, HOP_LENGTH)\n",
        "\n",
        "# load spectrogram + min max values\n",
        "with open(MIN_MAX_VALUES_PATH, \"rb\") as f:\n",
        "    min_max_values = pickle.load(f)\n",
        "\n",
        "specs, file_paths = load_fsdd(SPECTROGRAM_PATH)\n",
        "\n",
        "# sample spectrogram + min max values\n",
        "sampled_specs, sampled_min_max_values = select_spectrograms(specs,\n",
        "                                                            file_paths,\n",
        "                                                            min_max_values,\n",
        "                                                            5)\n",
        "\n",
        "# generate audio from sampled spectrogram\n",
        "signals, _ = sound_generator.generate(sampled_specs, sampled_min_max_values)\n",
        "\n",
        "# convert spectrogram samples to audio\n",
        "original_signals = sound_generator.convert_spectrograms_to_audio(\n",
        "    sampled_specs, sampled_min_max_values\n",
        ")\n",
        "\n",
        "# save audio signals\n",
        "save_signal(signals, SAVE_DIR_GENERATED)\n",
        "save_signal(original_signals, SAVE_DIR_ORIGNAL)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/data/spectrograms/4_george_29.wav.npy', '/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/data/spectrograms/1_lucas_45.wav.npy', '/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/data/spectrograms/3_george_19.wav.npy', '/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/data/spectrograms/0_yweweler_29.wav.npy', '/content/drive/MyDrive/Colab Notebooks/Sound Generation using VAE/data/spectrograms/0_theo_20.wav.npy']\n",
            "[{'min': -51.683426, 'max': 28.316572}, {'min': -55.34108, 'max': 24.658918}, {'min': -58.328014, 'max': 21.671986}, {'min': -68.99773, 'max': 11.002273}, {'min': -81.03109, 'max': -1.0310881}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yCmYdlMM5cx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}